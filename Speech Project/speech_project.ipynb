{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "main_ speech.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qQB7KUyrtpbQ",
        "outputId": "25752a95-bc44-4406-d0eb-00637b66577d"
      },
      "source": [
        "# 1\n",
        "from google.colab import drive\n",
        "drive.mount('/gdrive/')"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Mounted at /gdrive/\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "pclTPQrTv2vp"
      },
      "source": [
        "# 2\n",
        "import os \n",
        "import scipy \n",
        "import matplotlib.pyplot as plt \n",
        "import librosa\n",
        "import librosa.display\n",
        "import numpy as np\n",
        "from scipy.signal import filtfilt\n",
        "import warnings\n",
        "\n",
        "\n",
        "# from logmmse import logmmse_from_file\n",
        "\n",
        "warnings.filterwarnings(\"ignore\")"
      ],
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mEriZXIk0hf3"
      },
      "source": [
        "# 3\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.ensemble import RandomForestClassifier, AdaBoostClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from xgboost import XGBClassifier\n",
        "# import catboost as cbt\n",
        "from sklearn.neighbors import KNeighborsClassifier"
      ],
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MCE3n89Wv_XG"
      },
      "source": [
        "# 4\n",
        "def preProcessingBlock(file,a=1,plot=False):\n",
        "    # Pre-emphasis\n",
        "    signal,fs = librosa.load(file)\n",
        "    signal=np.asarray(signal)\n",
        "    pre_sig=filtfilt([1,-a],1,signal)\n",
        "    #Silent Remove Removal\n",
        "    return pre_sig, fs"
      ],
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4OZ6ZMyIwNm9",
        "outputId": "1634d4b2-3d56-4aaf-cc0f-fb7405ced90b"
      },
      "source": [
        "print(preProcessingBlock(\"/gdrive/My Drive/temp.wav\"))"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(array([ 0.        , -0.03790172,  0.01789165, ...,  0.00233766,\n",
            "       -0.01157563,  0.        ]), 22050)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "v4jtPkyAwsdC"
      },
      "source": [
        "# 5\n",
        "def framing(file,window='hann',frameLength=20,shiftFrame=25):\n",
        "    # signal,fs = librosa.load(file)\n",
        "    # signal=np.asarray(signal)\n",
        "    signal, fs = preProcessingBlock(file)\n",
        "    sigLen=len(list(signal))\n",
        "    outFrames=[]\n",
        "    N=int(frameLength*fs/1000)\n",
        "    Nshift=int(shiftFrame*fs/1000)\n",
        "    window=scipy.signal.hann(N)\n",
        "\n",
        "    numFrames=int(np.floor((sigLen-N)/Nshift) +1 )\n",
        "    \n",
        "    for i in range(0,numFrames):\n",
        "        sigSlice=signal[N*i:(i+1)*N]\n",
        "        # frame=np.dot(window,sigSlice)\n",
        "        frame = map(lambda x,y: x*y, window, sigSlice)\n",
        "        outFrames.append(list(frame))\n",
        "    return(outFrames, fs)"
      ],
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OlbxxM4Jwtj4",
        "outputId": "766f54f8-9711-4666-c6aa-292cf1c725c5"
      },
      "source": [
        "temp, fs = framing(\"/gdrive/My Drive/temp.wav\")\n",
        "temp = np.array(temp)\n",
        "print(temp, temp.shape, fs)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[[ 0.00000000e+00 -1.93217275e-06  3.64817218e-06 ... -1.53387785e-06\n",
            "  -8.53783943e-07  0.00000000e+00]\n",
            " [-0.00000000e+00  9.56056295e-07 -7.13717929e-07 ...  5.00654520e-06\n",
            "  -5.19896778e-07 -0.00000000e+00]\n",
            " [ 0.00000000e+00 -1.51263983e-06  3.80351191e-06 ... -4.43752273e-06\n",
            "   7.47876529e-07 -0.00000000e+00]\n",
            " ...\n",
            " [ 0.00000000e+00  6.63674321e-07 -1.46760142e-07 ...  1.60983216e-06\n",
            "  -9.95269893e-07  0.00000000e+00]\n",
            " [ 0.00000000e+00 -7.72266061e-07  5.49970414e-06 ...  1.93370568e-06\n",
            "  -2.07988195e-07 -0.00000000e+00]\n",
            " [-0.00000000e+00 -4.77853620e-08  1.63587144e-06 ...  1.17646856e-07\n",
            "  -6.33977430e-07  0.00000000e+00]] (1434, 441) 22050\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9g2kMZa3Fskq"
      },
      "source": [
        "# 6\n",
        "from scipy.linalg import toeplitz\n",
        "from scipy.signal import filtfilt\n",
        "def autocorr(x):\n",
        "    result = np.correlate(x, x, mode='full')\n",
        "    # print(result)\n",
        "    return result[(int)(result.size/2):]\n",
        "\n",
        "def lpcCoeffs(data,orderLPC=13,window='hann',G=1):\n",
        "    # data,fs = librosa.load(frame)\n",
        "    # signal=np.asarray(data)\n",
        "    sigLen=len((list(data)))\n",
        "    window = scipy.signal.hann(sigLen,True)\n",
        "    \n",
        "    # sigLPC=np.dot(window,data)\n",
        "    sigLPC = list(map(lambda x,y: x*y, window, data))\n",
        "    # print(sigLPC)\n",
        "    sigEnergy=sum(np.power(sigLPC,2))\n",
        "\n",
        "    # LPC Analysis \n",
        "    autoCorr=autocorr(sigLPC)\n",
        "    sigCorr=autoCorr/np.max(abs(autoCorr))\n",
        "\n",
        "    A=sigCorr[1:orderLPC-1]\n",
        "    A=toeplitz(A)\n",
        "    A=(-1)*np.linalg.inv(A)\n",
        "\n",
        "    r=sigCorr[2:orderLPC]\n",
        "    rT=np.transpose(r)\n",
        "  \n",
        "    L=np.transpose(np.dot(rT,A))\n",
        "    # Coefficeint Extraction\n",
        "    # print(L)\n",
        "    # lpcs=np.concatenate((np.array([1]),L),axis=0)\n",
        "    lpcs = np.array([1] + list(L))\n",
        "    # Signal Filtering \n",
        "    tempo = np.array([0] + list(-1*lpcs[2:]))\n",
        "\n",
        "    filteredSig=filtfilt(tempo,G,sigLPC)\n",
        "\n",
        "    #Residual Computation \n",
        "    lpResidual=sigLPC-filteredSig\n",
        "    return(lpResidual)\n",
        "\n",
        "\n",
        "def fileLPCRes(fi,orderLPC=13,window='hann',G=1):\n",
        "    print(\"Hello\")\n",
        "    outFrames, fs = framing(fi)\n",
        "    \n",
        "    print(np.array(outFrames).shape)\n",
        "    fileres=[]\n",
        "    # Now, frame-wise LPC caluclation \n",
        "    for i in range(0,len(outFrames)):\n",
        "        frame_lpres=lpcCoeffs(np.asarray(outFrames[i]))\n",
        "        fileres.append(frame_lpres)\n",
        "\n",
        "    return np.asarray(fileres), fs"
      ],
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "FknfQTxUF0lX",
        "outputId": "da156242-e5aa-42e5-dc48-322f44ba87ad"
      },
      "source": [
        "temp, fs = fileLPCRes(\"/gdrive/My Drive/temp.wav\")\n",
        "temp = np.array(temp)\n",
        "print(temp, temp.shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n",
            "(1434, 441)\n",
            "[[-1.05879118e-22  1.21779179e-06  2.46313089e-06 ... -1.67379390e-06\n",
            "  -5.89441255e-07 -7.94093388e-23]\n",
            " [ 1.27054942e-21  5.90134984e-06 -3.65605620e-06 ...  4.67951460e-06\n",
            "  -1.54794350e-06 -8.47032947e-22]\n",
            " [ 0.00000000e+00 -1.45771296e-07  7.58471258e-08 ... -9.71085678e-07\n",
            "   9.90381797e-07  5.29395592e-23]\n",
            " ...\n",
            " [ 0.00000000e+00 -3.78625355e-07  1.77178436e-06 ...  5.84188043e-08\n",
            "   1.90415827e-07  7.94093388e-23]\n",
            " [ 1.32348898e-22 -1.26572729e-06  2.29602533e-06 ... -1.63628588e-06\n",
            "   1.00181258e-06  5.29395592e-23]\n",
            " [-0.00000000e+00 -3.57761749e-08  8.26779494e-08 ...  7.49233036e-08\n",
            "   5.36596458e-08  1.65436123e-24]] (1434, 441)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xrkvkcG91kWl"
      },
      "source": [
        "# 7\n",
        "def mfcc(y,sr=22050, S=None, n_mfcc=15, dct_type=2, norm='ortho',flag=False):\n",
        "    # y,sr = librosa.load(file)\n",
        "    mfccs = librosa.feature.mfcc(y=y,sr=sr, n_mfcc=n_mfcc)\n",
        "\n",
        "    if(flag):\n",
        "        print('Plotting the spectrogram')\n",
        "        plt.figure(figsize=(10, 4))\n",
        "        librosa.display.specshow(mfccs, x_axis='time')\n",
        "        plt.colorbar()\n",
        "        plt.title('MFCC')\n",
        "        plt.tight_layout()\n",
        "        plt.show()\n",
        "\n",
        "    return(mfccs)"
      ],
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "07rnp3rB4-db",
        "outputId": "bcf7a154-b563-4d2d-a369-12ab8a2145e4"
      },
      "source": [
        "print(mfcc(temp[1]).shape)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(15, 1)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "XTdDb-YAGsgb"
      },
      "source": [
        "# 8\n",
        "X = []\n",
        "Y = []\n",
        "test_paths = []"
      ],
      "execution_count": 9,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6JevFtNUAvRP",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "1993bf5c-2087-419d-d5cb-70140aaf6f59"
      },
      "source": [
        "# FRAME BY FRAME\n",
        "# 12\n",
        "import os, random\n",
        "random.seed(42)\n",
        "positive_path = \"/gdrive/My Drive/speech/spasmodic dysphonia_temp\"\n",
        "\n",
        "for fi in os.listdir(positive_path):\n",
        "  path = os.path.join(positive_path, fi)\n",
        "  if random.random() >= 0.6:\n",
        "    test_paths.append((path, 1))\n",
        "    continue\n",
        "  temp, fs = fileLPCRes(path)\n",
        "  temp = np.array(temp)\n",
        "  # temp_signal, fs = preProcessingBlock(path)\n",
        "  # peaks = get_peaks(temp_signal, 22050, 10 * 0.0001, 100)\n",
        "  # print(peaks)\n",
        "  # jitt = get_jitt(peaks)\n",
        "  # shim = get_shim_2(peaks)\n",
        "  # print(temp, temp.shape, fs)\n",
        "\n",
        "  hnrs = params(path)\n",
        "  for arr, hnr in zip(temp, hnrs):\n",
        "    # mf = list(mfcc(arr)) + [jitt, shim]\n",
        "    mf = list(mfcc(arr)) + [hnr]\n",
        "    X.append(mf)\n",
        "    Y.append(1)"
      ],
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n",
            "(1653, 441)\n",
            "Hello\n",
            "(1296, 441)\n",
            "Hello\n",
            "(974, 441)\n",
            "Hello\n",
            "(1216, 441)\n",
            "Hello\n",
            "(1057, 441)\n",
            "Hello\n",
            "(1018, 441)\n",
            "Hello\n",
            "(999, 441)\n",
            "Hello\n",
            "(967, 441)\n",
            "Hello\n",
            "(737, 441)\n",
            "Hello\n",
            "(937, 441)\n",
            "Hello\n",
            "(1020, 441)\n",
            "Hello\n",
            "(1920, 441)\n",
            "Hello\n",
            "(905, 441)\n",
            "Hello\n",
            "(724, 441)\n",
            "Hello\n",
            "(1175, 441)\n",
            "Hello\n",
            "(1116, 441)\n",
            "Hello\n",
            "(1008, 441)\n",
            "Hello\n",
            "(928, 441)\n",
            "Hello\n",
            "(1465, 441)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nsqsiM4eLxzr"
      },
      "source": [
        "# CONCAT ALL FRAMES\n",
        "\n",
        "# import os, random\n",
        "positive_path = \"/gdrive/My Drive/speech/spasmodic dysphonia_temp\"\n",
        "\n",
        "for fi in os.listdir(positive_path):\n",
        "  path = os.path.join(positive_path, fi)\n",
        "  if random.random() >= 0.6:\n",
        "    test_paths.append((path, 1))\n",
        "    continue\n",
        "  temp, fs = framing(path)\n",
        "  temp = np.array(temp)\n",
        "  curr = []\n",
        "  for arr in temp:\n",
        "    curr.append(mfcc(arr))\n",
        "  curr = np.array(curr).reshape(-1,15)\n",
        "  # print(curr.reshape(-1,15).shape)\n",
        "  Y.append(1)\n",
        "  X.append(curr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "A16gfRFYHFaS",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "6f7ce346-6afd-4c45-827a-69cac9d9103e"
      },
      "source": [
        "# FRAME BY FRAME\n",
        "# 13\n",
        "import os\n",
        "negative_path = \"/gdrive/My Drive/speech/Healthy_temp\"\n",
        "\n",
        "for fi in os.listdir(negative_path):\n",
        "  path = os.path.join(negative_path, fi)\n",
        "  if random.random() >= 0.6:\n",
        "    test_paths.append((path, 0))\n",
        "    continue\n",
        "  temp, fs = fileLPCRes(path)\n",
        "  temp = np.array(temp)\n",
        "  # temp_signal, fs = preProcessingBlock(path)\n",
        "  # peaks = get_peaks(temp_signal, 22050, 10 * 0.0001, 100)\n",
        "  # # print(peaks)\n",
        "  # jitt = get_jitt(peaks)\n",
        "  # shim = get_shim_2(peaks)\n",
        "  # print(temp, temp.shape, fs)\n",
        "\n",
        "  hnrs = params(path)\n",
        "  for arr, hnr in zip(temp, hnrs):\n",
        "    # mf = list(mfcc(arr)) + [jitt, shim]\n",
        "    mf = list(mfcc(arr)) + [hnr]\n",
        "    X.append(mf)\n",
        "    Y.append(0)"
      ],
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n",
            "(892, 441)\n",
            "Hello\n",
            "(1209, 441)\n",
            "Hello\n",
            "(1338, 441)\n",
            "Hello\n",
            "(1552, 441)\n",
            "Hello\n",
            "(1824, 441)\n",
            "Hello\n",
            "(991, 441)\n",
            "Hello\n",
            "(1365, 441)\n",
            "Hello\n",
            "(1461, 441)\n",
            "Hello\n",
            "(1528, 441)\n",
            "Hello\n",
            "(1259, 441)\n",
            "Hello\n",
            "(1216, 441)\n",
            "Hello\n",
            "(1570, 441)\n",
            "Hello\n",
            "(1434, 441)\n",
            "Hello\n",
            "(1951, 441)\n",
            "Hello\n",
            "(1702, 441)\n",
            "Hello\n",
            "(1159, 441)\n",
            "Hello\n",
            "(1245, 441)\n",
            "Hello\n",
            "(1274, 441)\n",
            "Hello\n",
            "(1734, 441)\n",
            "Hello\n",
            "(1270, 441)\n",
            "Hello\n",
            "(1059, 441)\n",
            "Hello\n",
            "(1623, 441)\n",
            "Hello\n",
            "(1052, 441)\n",
            "Hello\n",
            "(1273, 441)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oYtGb6tPL_NZ"
      },
      "source": [
        "# CONCAT ALL FRAMES\n",
        "# NR\n",
        "\n",
        "import os\n",
        "negative_path = \"/gdrive/My Drive/speech/Healthy_temp\"\n",
        "\n",
        "for fi in os.listdir(negative_path):\n",
        "  path = os.path.join(negative_path, fi)\n",
        "  if random.random() >= 0.6:\n",
        "    test_paths.append((path, 0))\n",
        "    continue\n",
        "  temp, fs = framing(path)\n",
        "  temp = np.array(temp)\n",
        "  curr = []\n",
        "  # print(temp, temp.shape, fs)\n",
        "  for arr in temp:\n",
        "    curr.append(mfcc(arr))\n",
        "  curr = np.array(curr).reshape(-1, 15)\n",
        "  X.append(curr)\n",
        "  Y.append(0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qrW8Dqc2POZE",
        "outputId": "31fdfe43-56d2-4c4d-fc80-b21d3ac615fd"
      },
      "source": [
        "# 14\n",
        "X = np.array(X)\n",
        "Y = np.array(Y)\n",
        "test = X.reshape((-1, 16))\n",
        "print(test.shape, Y.shape)"
      ],
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54096, 16) (54096,)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "tJAkTRa2OmTS"
      },
      "source": [
        "# print(X[0].shape)\n",
        "#NR\n",
        "T = []\n",
        "for i in X:\n",
        "  print(i.flatten().shape)\n",
        "  T.append(i.flatten())\n",
        "T = np.array(T)\n",
        "\n",
        "import tensorflow as tf\n",
        "test = tf.keras.preprocessing.sequence.pad_sequences(T,truncating=\"post\", padding=\"post\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TP7R0QY7HuZJ"
      },
      "source": [
        "from sklearn.svm import SVC\n",
        "# svm_model = SVC(kernel = 'rbf', C=1)\n",
        "svm_model = SVC(kernel = 'rbf', C=1, class_weight=\"balanced\")\n",
        "svm_model = svm_model.fit(X=test, y=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TZ-oULCq2AOQ"
      },
      "source": [
        "#15\n",
        "# logistic_model = LogisticRegression()\n",
        "logistic_model = LogisticRegression(class_weight=\"balanced\")\n",
        "logistic_model = logistic_model.fit(X=test, y=Y)"
      ],
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yXvpDIJT2Kg5"
      },
      "source": [
        "# randomf_model = RandomForestClassifier(n_estimators=200, class_weight=\"balanced\")\n",
        "randomf_model = RandomForestClassifier(n_estimators=200)\n",
        "randomf_model = randomf_model.fit(X=test, y=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MbCSIoQs4cPf"
      },
      "source": [
        "xgb_model = XGBClassifier()\n",
        "# xgb_model = XGBClassifier(class_weight='balanced')\n",
        "xgb_model = xgb_model.fit(X=test, y=Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Nu6EuXt61XXq"
      },
      "source": [
        "from sklearn.mixture import GaussianMixture\n",
        "gaussian_model = GaussianMixture(max_iter=500, n_components=2)\n",
        "gaussian_model = gaussian_model.fit(test, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LPWaM64q2Ym1"
      },
      "source": [
        "knn_model = KNeighborsClassifier(n_neighbors = 100)\n",
        "knn_model = knn_model.fit(test, Y)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BAkTTa9NOL95",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "40b35855-cdb8-4215-c324-3a7d3b2c67ba"
      },
      "source": [
        "# 16\n",
        "print(test.shape)\n",
        "corrects = 0\n",
        "incorr = 0"
      ],
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "(54096, 16)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PpmOlfX0Ismo"
      },
      "source": [
        "# 17\n",
        "test_X = []\n",
        "test_Y = []"
      ],
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6TiTo4ZTKi6e",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "47974d88-7474-428e-a990-d53fe808f91f"
      },
      "source": [
        "# 18\n",
        "for fi, label in test_paths:\n",
        "  temp, fs = fileLPCRes(fi)\n",
        "  temp = np.array(temp)\n",
        "  # print(temp, temp.shape, fs)\n",
        "  # dic = {}\n",
        "  temper = []\n",
        "  # temp_signal, fs = preProcessingBlock(fi)\n",
        "  # peaks = get_peaks(temp_signal, 22050, 10 * 0.0001, 100)\n",
        "  # # print(peaks)\n",
        "  # jitt = get_jitt(peaks)\n",
        "  # shim = get_shim_2(peaks)\n",
        "  \n",
        "  # for arr in temp:\n",
        "  #   # fr = list(mfcc(arr)) + [jitt, shim] \n",
        "  #   temper.append(mfcc(arr))\n",
        "  hnrs = params(path)\n",
        "  for arr, hnr in zip(temp, hnrs):\n",
        "    # mf = list(mfcc(arr)) + [jitt, shim]\n",
        "    mf = list(mfcc(arr)) + [hnr]\n",
        "    temper.append(mf)\n",
        "  test_X.append(temper)\n",
        "  test_Y.append(label)\n",
        "    # print(np.array([fr]).shape)\n",
        "    # lab = logistic_model.predict(np.array([fr]).reshape(1,15))\n",
        "    # dic[lab[0]] = dic.get(lab[0], 0) + 1\n",
        "  # lab = max(dic, key=dic.get)\n",
        "  # if lab == label:\n",
        "    # corrects += 1\n",
        "  # else:\n",
        "    # incorr += 1"
      ],
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Hello\n",
            "(1295, 441)\n",
            "Hello\n",
            "(984, 441)\n",
            "Hello\n",
            "(791, 441)\n",
            "Hello\n",
            "(1281, 441)\n",
            "Hello\n",
            "(696, 441)\n",
            "Hello\n",
            "(1179, 441)\n",
            "Hello\n",
            "(835, 441)\n",
            "Hello\n",
            "(1466, 441)\n",
            "Hello\n",
            "(905, 441)\n",
            "Hello\n",
            "(987, 441)\n",
            "Hello\n",
            "(1314, 441)\n",
            "Hello\n",
            "(1644, 441)\n",
            "Hello\n",
            "(1622, 441)\n",
            "Hello\n",
            "(1404, 441)\n",
            "Hello\n",
            "(1763, 441)\n",
            "Hello\n",
            "(1705, 441)\n",
            "Hello\n",
            "(1596, 441)\n",
            "Hello\n",
            "(1246, 441)\n",
            "Hello\n",
            "(1400, 441)\n",
            "Hello\n",
            "(1524, 441)\n",
            "Hello\n",
            "(1195, 441)\n",
            "Hello\n",
            "(1624, 441)\n",
            "Hello\n",
            "(1042, 441)\n",
            "Hello\n",
            "(1452, 441)\n",
            "Hello\n",
            "(1051, 441)\n",
            "Hello\n",
            "(1168, 441)\n",
            "Hello\n",
            "(1498, 441)\n",
            "Hello\n",
            "(1120, 441)\n",
            "Hello\n",
            "(1470, 441)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "wgtcRhhWIr3d"
      },
      "source": [
        "# 19\n",
        "pred = []\n",
        "for fi, label in zip(test_X, test_Y):\n",
        "  # temp, fs = framing(fi)\n",
        "  temp = np.array(fi)\n",
        "  # print(temp, temp.shape, fs)\n",
        "  dic = {}\n",
        "  for arr in temp:\n",
        "    lab = logistic_model.predict(np.array([arr]).reshape(1,16))\n",
        "    dic[lab[0]] = dic.get(lab[0], 0) + 1\n",
        "  lab = max(dic, key=dic.get)\n",
        "  pred.append(lab)\n",
        "  if lab == label:\n",
        "    corrects += 1\n",
        "  else:\n",
        "    incorr += 1"
      ],
      "execution_count": 24,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "hpgQh6HtSOVv",
        "outputId": "d46f5624-5da1-40e4-e15b-935fcdf210e4"
      },
      "source": [
        "# 20\n",
        "from sklearn.metrics import classification_report, accuracy_score\n",
        "print(classification_report(test_Y, pred))\n",
        "print(accuracy_score(test_Y, pred))"
      ],
      "execution_count": 25,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.72      0.81        18\n",
            "           1       0.67      0.91      0.77        11\n",
            "\n",
            "    accuracy                           0.79        29\n",
            "   macro avg       0.80      0.82      0.79        29\n",
            "weighted avg       0.83      0.79      0.80        29\n",
            "\n",
            "0.7931034482758621\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Io4F4DtMRmqz",
        "outputId": "1a911cd7-8e90-4551-f5ac-0aeb13dad507"
      },
      "source": [
        "print(incorr, corrects)"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "3 26\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "_KWFKSMsd3ri"
      },
      "source": [
        "## CONCATENATE\n",
        "for fi, label in test_paths:\n",
        "  temp, fs = framing(fi)\n",
        "  temp = np.array(temp)\n",
        "  # print(temp, temp.shape, fs)\n",
        "  # dic = {}\n",
        "  # for arr in temp:\n",
        "  #   fr = mfcc(arr)\n",
        "  #   # print(np.array([fr]).shape)\n",
        "  #   lab = model.predict(np.array([fr]).reshape(1,15))\n",
        "  #   dic[lab[0]] = dic.get(lab[0], 0) + 1\n",
        "  # lab = max(dic, key=dic.get)\n",
        "\n",
        "  curr = []\n",
        "  # print(temp, temp.shape, fs)\n",
        "  for arr in temp:\n",
        "    curr.append(mfcc(arr))\n",
        "  curr = np.array(curr).reshape(-1, 15)\n",
        "  x_test = tf.keras.preprocessing.sequence.pad_sequences(np.array([curr.flatten()]),truncating=\"post\", padding=\"post\", maxlen=29265)\n",
        "  print(x_test.shape)\n",
        "  lab = model.predict(x_test)\n",
        "  if lab == label:\n",
        "    corrects += 1\n",
        "  else:\n",
        "    incorr += 1"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 69
        },
        "id": "RmINSxwe8_U0",
        "outputId": "5cb3098d-70f4-4131-f465-e4939458c05f"
      },
      "source": [
        "# 9\n",
        "import numpy as np\n",
        "from scipy import signal\n",
        "from math import log10 as log\n",
        "\n",
        "\n",
        "def get_number_of_windows(total_len, win_len):\n",
        "\n",
        "\tif total_len % win_len == 0:\n",
        "\t\treturn total_len / win_len\n",
        "\treturn (total_len / win_len) + 1\n",
        "\n",
        "def get_peaks(input_sound, freq, window_size_time,samples_to_check):\n",
        "\tpeaks = []\n",
        "\tprint(input_sound)\n",
        "\tinput_sound = signal.detrend(input_sound)\n",
        "\tprint(\"Input after detrending: \", input_sound)\n",
        "\tinput_sound = np.absolute(input_sound)\n",
        "\tsize_of_window = int(freq*window_size_time)\n",
        "\tsize_of_signal = len(input_sound)\n",
        "\n",
        "\tnum_windows = int(get_number_of_windows(size_of_signal, size_of_window))\n",
        "\tprint(num_windows)\n",
        "\tfor i in range(num_windows):\n",
        "\t\tbase_index = i*size_of_window\n",
        "\t\tcurr_window = input_sound[i*size_of_window:(i+1)*size_of_window]\n",
        "\t\tmoving_avgs = []\n",
        "\t\tsum_ = 0\n",
        "\t\tfor i, elem in enumerate(curr_window):\n",
        "\t\t\tsum_ += elem\n",
        "\t\t\tmoving_avgs.append(sum_/(i+1))\n",
        "\t\tmoving_avgs = np.array(moving_avgs)\n",
        "\t\tmax_ind = moving_avgs.argmax()\n",
        "\n",
        "\t\tleft_bound = max(0, max_ind-samples_to_check+base_index)\n",
        "\t\tright_bound = max_ind+samples_to_check+base_index\n",
        "\n",
        "\t\tsubsignal_to_check = input_sound[left_bound: right_bound+1]\n",
        "\t\t# print(subsignal_to_check, subsignal_to_check.argmax())\n",
        "\t\tmax_in_subsignal = subsignal_to_check.argmax()\n",
        "\t\tpeaks.append((left_bound+max_in_subsignal, subsignal_to_check[max_in_subsignal]))\n",
        "  \n",
        "\treturn np.array(peaks)\n",
        "\n",
        "def get_jitt(peaks):\n",
        "\n",
        "\tN = len(peaks)\n",
        "\tjitt_den = np.sum(peaks, axis=0)[0]\n",
        "\tjitta_numerator = 0\n",
        "\tfor i in range(1, N):\n",
        "\t\tjitta_numerator += abs(peaks[i][0] - peaks[i-1][0])\n",
        "\n",
        "\treturn (100 * N * jitta_numerator)/((N-1)*jitt_den)\n",
        "\n",
        "def get_shim(peaks):\n",
        "\n",
        "\tN = len(peaks)\n",
        "\tshim_den = np.sum(peaks, axis=0)[1]\n",
        "\tshim_numerator = 0\n",
        "\tfor i in range(1, N):\n",
        "\t\tshim_numerator += abs(peaks[i][1] - peaks[i-1][1])\n",
        "\n",
        "\treturn (100 * N * shim_numerator)/((N-1)*shim_den)\n",
        "\n",
        "def get_shim_2(peaks):\n",
        "\n",
        "\tN = len(peaks)\n",
        "\tshim_numerator = 0\n",
        "\tfor i in range(1, N):\n",
        "\t\tshim_numerator += abs(log(peaks[i][1]/peaks[i-1][1]))\n",
        "\n",
        "\treturn (20 * shim_numerator)/(N-1)\n",
        "\n",
        "\n",
        "\n",
        "\n",
        "#### DOUBTS\n",
        "# 1. Detrend and then absolute or reverse\n",
        "# 2. Indices in jitt and shim are slighly confusing\n",
        "# 3. Can there be duplicates in peaks\n",
        "\n",
        "\n",
        "'''\n",
        "Testing : \n",
        "\n",
        "window_size_time = 10 * 0.0001\n",
        "# input_sound_vector = np.random.randint(10, size=(20))\n",
        "# input_sound_vector = np.random.rand(300)\n",
        "input_sound_vector = np.array([9, 0, 9, 8, 3, 0, 9, 0, 4, 1, 7, 1, 6, 0, 9, 7, 0, 1, 9, 1])\n",
        "samples_to_check = 3\n",
        "frequency = 5000\n",
        "\n",
        "\n",
        "print(\"Input: \", input_sound_vector)\n",
        "peaks = get_peaks(input_sound_vector, frequency)\n",
        "print(\"Peak indexes and values: \", peaks)\n",
        "jitt = get_jitt(peaks)\n",
        "shim = get_shim(peaks)\n",
        "print(\"Jitt value is : \", jitt)\n",
        "print(\"Shim value is : \", shim)\n",
        "\n",
        "'''"
      ],
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'\\nTesting : \\n\\nwindow_size_time = 10 * 0.0001\\n# input_sound_vector = np.random.randint(10, size=(20))\\n# input_sound_vector = np.random.rand(300)\\ninput_sound_vector = np.array([9, 0, 9, 8, 3, 0, 9, 0, 4, 1, 7, 1, 6, 0, 9, 7, 0, 1, 9, 1])\\nsamples_to_check = 3\\nfrequency = 5000\\n\\n\\nprint(\"Input: \", input_sound_vector)\\npeaks = get_peaks(input_sound_vector, frequency)\\nprint(\"Peak indexes and values: \", peaks)\\njitt = get_jitt(peaks)\\nshim = get_shim(peaks)\\nprint(\"Jitt value is : \", jitt)\\nprint(\"Shim value is : \", shim)\\n\\n'"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 10
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H3LPlEU-9BJo",
        "outputId": "e03dd6d4-c41b-4c5e-9fa9-f09bd5848449"
      },
      "source": [
        "# 10\n",
        "temp_signal, fs = preProcessingBlock(\"/gdrive/My Drive/temp.wav\")\n",
        "print(len(temp_signal))\n",
        "window_size_time = 10 * 0.0001\n",
        "samples_to_check = 5\n",
        "peaks = get_peaks(temp_signal, 22050, 10 * 0.0001, 100)\n",
        "print(peaks)\n",
        "jitt = get_jitt(peaks)\n",
        "shim = get_shim_2(peaks)\n",
        "print(\"Jitt value is : \", jitt)\n",
        "print(\"Shim value is : \", shim)"
      ],
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "638879\n",
            "[ 0.         -0.03989409  0.02428077 ... -0.00076317  0.00315938\n",
            "  0.        ]\n",
            "Input after detrending:  [ 7.36636634e-08 -3.98940117e-02  2.42808434e-02 ... -7.63215374e-04\n",
            "  3.15933277e-03 -4.96098164e-08]\n",
            "29040\n",
            "[[2.60000000e+01 4.19624903e-02]\n",
            " [2.60000000e+01 4.19624903e-02]\n",
            " [2.60000000e+01 4.19624903e-02]\n",
            " ...\n",
            " [6.38877000e+05 3.15933277e-03]\n",
            " [6.38877000e+05 3.15933277e-03]\n",
            " [6.38877000e+05 3.15933277e-03]]\n",
            "Jitt value is :  0.006887085276814954\n",
            "Shim value is :  0.25721444982928887\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7Ty44tTTGmD4",
        "outputId": "70ca8d49-a3db-4c23-efab-9e0d84c60b0b"
      },
      "source": [
        "#  11\n",
        "!pip3 install Signal_Analysis\n",
        "from Signal_Analysis.features.signal import get_F_0\n",
        "from Signal_Analysis.features.signal  import get_HNR\n",
        "\n",
        "def params(fi):\n",
        "    temp, fs = framing(fi)\n",
        "    # te, fs = fileLPCRes(fi)\n",
        "    # print(len(temp), len(te))\n",
        "    temp=np.asarray(temp)\n",
        "    f0_frame=[]\n",
        "    hnr_frame=[]\n",
        "    for i in range(0,temp.shape[0]):\n",
        "        hnrFrame=get_HNR(temp[i][:],fs)\n",
        "        hnr_frame.append(hnrFrame)\n",
        "    return(hnr_frame)\n",
        "H=params(\"/gdrive/My Drive/temp.wav\")\n",
        "print(len(H))"
      ],
      "execution_count": 12,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting Signal_Analysis\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/9b/77/f395f3d5a70394de295889b70551497852787e19f4cf5940fa9709151497/Signal_Analysis-0.1.26.tar.gz (378kB)\n",
            "\r\u001b[K     |▉                               | 10kB 15.4MB/s eta 0:00:01\r\u001b[K     |█▊                              | 20kB 19.8MB/s eta 0:00:01\r\u001b[K     |██▋                             | 30kB 13.1MB/s eta 0:00:01\r\u001b[K     |███▌                            | 40kB 9.6MB/s eta 0:00:01\r\u001b[K     |████▎                           | 51kB 4.6MB/s eta 0:00:01\r\u001b[K     |█████▏                          | 61kB 4.8MB/s eta 0:00:01\r\u001b[K     |██████                          | 71kB 5.4MB/s eta 0:00:01\r\u001b[K     |███████                         | 81kB 5.8MB/s eta 0:00:01\r\u001b[K     |███████▉                        | 92kB 5.6MB/s eta 0:00:01\r\u001b[K     |████████▋                       | 102kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████▌                      | 112kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████▍                     | 122kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████▎                    | 133kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████                    | 143kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████                   | 153kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████▉                  | 163kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████▊                 | 174kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████▋                | 184kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████▍               | 194kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████▎              | 204kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████▏             | 215kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████             | 225kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████            | 235kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████▊           | 245kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████▋          | 256kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████▌         | 266kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████▍        | 276kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████▏       | 286kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████       | 296kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████      | 307kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████▉     | 317kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████▊    | 327kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████▌   | 337kB 5.9MB/s eta 0:00:01\r\u001b[K     |█████████████████████████████▍  | 348kB 5.9MB/s eta 0:00:01\r\u001b[K     |██████████████████████████████▎ | 358kB 5.9MB/s eta 0:00:01\r\u001b[K     |███████████████████████████████▏| 368kB 5.9MB/s eta 0:00:01\r\u001b[K     |████████████████████████████████| 378kB 5.9MB/s \n",
            "\u001b[?25hRequirement already satisfied: numpy in /usr/local/lib/python3.6/dist-packages (from Signal_Analysis) (1.18.5)\n",
            "Collecting peakutils\n",
            "  Downloading https://files.pythonhosted.org/packages/0a/11/6416c8aebba4d5f73e23e1f070a419a8944f3ba17eed9efdf9cdc95f0411/PeakUtils-1.3.3-py3-none-any.whl\n",
            "Requirement already satisfied: scipy in /usr/local/lib/python3.6/dist-packages (from peakutils->Signal_Analysis) (1.4.1)\n",
            "Building wheels for collected packages: Signal-Analysis\n",
            "  Building wheel for Signal-Analysis (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for Signal-Analysis: filename=Signal_Analysis-0.1.26-cp36-none-any.whl size=14538 sha256=ce0ecec8485046ecd495abe7872e3b12ceb151be869fda040422774997bbdc63\n",
            "  Stored in directory: /root/.cache/pip/wheels/50/06/bb/04aa9ef50b93b5961b9817600ca1ff379f7091e63e09831655\n",
            "Successfully built Signal-Analysis\n",
            "Installing collected packages: peakutils, Signal-Analysis\n",
            "Successfully installed Signal-Analysis-0.1.26 peakutils-1.3.3\n",
            "1159\n"
          ],
          "name": "stdout"
        }
      ]
    }
  ]
}